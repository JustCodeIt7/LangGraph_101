{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e8c9e0ed-a1c7-4cb8-b1b5-5ed32e9f240b",
   "metadata": {},
   "source": [
    " ## Human-in-the-loop Advanced  \n",
    "\n",
    "Human-in-the-loop capabilities are a core feature of LangGraph, allowing for human intervention at any point in a workflow. This is crucial for validating, correcting, or providing additional context to the output of Large Language Models (LLMs), especially for tasks like reviewing and approving tool calls.\n",
    "\n",
    "### Core Concepts\n",
    "\n",
    "LangGraph's human-in-the-loop functionality is built on two key concepts: persistent state and the ability to pause execution.\n",
    "\n",
    "*   **Persistent Execution State:** LangGraph can pause and resume workflows indefinitely. It achieves this by saving the graph's state at each step (a process called \"checkpointing\"). This allows for asynchronous human review without time limits.\n",
    "*   **Pausing Mechanisms:** You can pause a graph in two ways:\n",
    "    *   **Dynamic Interrupts:** Using the `interrupt()` function within a node to pause the graph based on its current state. **This is the recommended method for production workflows.**\n",
    "    *   **Static Interrupts:** Using `interrupt_before` and `interrupt_after` to pause the graph at predefined nodes. This is primarily used for debugging."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dcac100a-686c-442c-981c-8cbdd3a62600",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Load packages\n",
    "import os\n",
    "from langchain.chat_models import init_chat_model\n",
    "from typing import Annotated\n",
    "from langchain_core.tools import tool\n",
    "from typing_extensions import TypedDict\n",
    "from langgraph.checkpoint.memory import InMemorySaver\n",
    "from langgraph.graph import StateGraph, START\n",
    "from langgraph.graph.message import add_messages\n",
    "from langgraph.prebuilt import ToolNode, tools_condition\n",
    "from langgraph.types import Command, interrupt\n",
    "from IPython.display import Image, display\n",
    "from dotenv import load_dotenv\n",
    "from rich import print\n",
    "# 2. Setup: Load API keys and initialize the language model.\n",
    "load_dotenv()\n",
    "llm = init_chat_model(\"ollama:llama3.2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
