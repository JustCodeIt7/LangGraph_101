{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e8c9e0ed-a1c7-4cb8-b1b5-5ed32e9f240b",
   "metadata": {},
   "source": [
    " # Human-in-the-loop with Terminal Confirmation \n",
    "\n",
    " This script builds a conversational agent that can pause to ask a human for\n",
    " confirmation via the terminal, and then resume its task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcac100a-686c-442c-981c-8cbdd3a62600",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Load packages\n",
    "import os\n",
    "from langchain.chat_models import init_chat_model\n",
    "from typing import Annotated\n",
    "from langchain_core.tools import tool\n",
    "from typing_extensions import TypedDict\n",
    "from langgraph.checkpoint.memory import InMemorySaver\n",
    "from langgraph.graph import StateGraph, START\n",
    "from langgraph.graph.message import add_messages\n",
    "from langgraph.prebuilt import ToolNode, tools_condition\n",
    "from langgraph.types import Command, interrupt\n",
    "from IPython.display import Image, display\n",
    "from dotenv import load_dotenv\n",
    "from rich import print\n",
    "# 2. Setup: Load API keys and initialize the language model.\n",
    "load_dotenv()\n",
    "llm = init_chat_model(\"ollama:llama3.2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fea2b251-3d00-4707-ba15-f42ae3c8300c",
   "metadata": {},
   "source": [
    "## Define State and Graph\n",
    "\n",
    "The state of the system serves as the agent’s memory, while the graph represents the agent’s workflow. A dictionary stores the conversation history, and the `add_messages` function facilitates the appending of new messages to this history."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b115c17-4d29-41a8-843a-5683c13ecf0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class State(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n",
    "\n",
    "# 4. Initialize the graph builder with the state's structure.\n",
    "graph_builder = StateGraph(State)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define and Bind Custom Tool:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "006b5ce7-add2-47d4-bab9-bb2c300226b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Define a custom tool for human confirmation using the `@tool` decorator.\n",
    "@tool\n",
    "def await_user_confirmation(prompt_to_user: str) -> str:\n",
    "    \"\"\"\n",
    "    Pauses the process and asks the human user for a 'yes' confirmation to proceed.\n",
    "    The tool will return the user's exact input.\n",
    "    \"\"\"\n",
    "    # The docstring tells the LLM how to use the tool.\n",
    "    \n",
    "    # `interrupt()` pauses the graph and passes data ('prompt') to the user.\n",
    "    human_response = interrupt({\"prompt\": prompt_to_user})\n",
    "    \n",
    "    # The value returned here is the human's input, which is sent back to the LLM.\n",
    "    return human_response[\"data\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ba300f9-1a11-4b2d-8a0a-6b16d226aab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Bind the tool to the LLM, making it available for the agent to call.\n",
    "tools = [await_user_confirmation]\n",
    "llm_with_tools = llm.bind_tools(tools)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Graph Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c301e0e-eb4a-468d-8113-41832204bbbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. Define Graph Nodes: Functions that represent steps in the workflow.\n",
    "# The 'chatbot' node calls the LLM to get the next action or response.\n",
    "def chatbot(state: State):\n",
    "    # Invokes the LLM with the current message history.\n",
    "    message = llm_with_tools.invoke(state[\"messages\"])\n",
    "    # Returns the LLM's message to be added to the state.\n",
    "    return {\"messages\": [message]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfa212ce-9bff-498e-ab99-7260d04832e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8. Build the graph: Define nodes and the edges that connect them.\n",
    "# Add the chatbot and tool execution nodes.\n",
    "graph_builder.add_node(\"chatbot\", chatbot)\n",
    "tool_node = ToolNode(tools=tools)\n",
    "graph_builder.add_node(\"tools\", tool_node)\n",
    "\n",
    "# Set the entry point for the graph.\n",
    "graph_builder.add_edge(START, \"chatbot\")\n",
    "\n",
    "# Define the logic for routing: after the chatbot runs, `tools_condition` checks\n",
    "# if a tool was called. If yes, it routes to the 'tools' node.\n",
    "graph_builder.add_conditional_edges(\"chatbot\", tools_condition)\n",
    "\n",
    "# After a tool is run, loop back to the chatbot to continue the conversation.\n",
    "graph_builder.add_edge(\"tools\", \"chatbot\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d34eba6c-5472-4e95-9a7d-4740269ca6ed",
   "metadata": {},
   "source": [
    " ## Compile and Visualize the Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66c3e48e-a25e-42cd-b4fa-fd66135c7626",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9. Compile the graph into a runnable object, using a memory saver for persistence.\n",
    "# The checkpointer is what allows the graph to be paused and resumed.\n",
    "memory = InMemorySaver()\n",
    "graph = graph_builder.compile(checkpointer=memory)\n",
    "\n",
    "# Optional: Display a visualization of the graph's structure.\n",
    "try:\n",
    "    display(Image(graph.get_graph().draw_mermaid_png()))\n",
    "except Exception:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bbce36e-fe61-4a7a-86c7-691d337ae0bf",
   "metadata": {},
   "source": [
    " ## Run the Graph and Wait for Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dc41fce-c754-4031-972a-97e2a3a1ac88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10. Start the agent.\n",
    "# The user prompt guides the LLM to use the confirmation tool at the correct time.\n",
    "# The `config` with `thread_id` makes the conversation stateful.\n",
    "user_input = (\n",
    "    \"\"\"\n",
    "    I want to write a short story about a robot who discovers music.\n",
    "    First, come up with a name for the robot and a title for the story.\n",
    "    Then, wait for me to say 'yes' before you write the actual story.\n",
    "    \"\"\"\n",
    ")\n",
    "config = {\"configurable\": {\"thread_id\": \"4\"}}\n",
    "\n",
    "print(\"--- Starting AI ---\")\n",
    "# Execute the graph. `stream` returns an iterator of all events as they happen.\n",
    "events = graph.stream(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": user_input}]},\n",
    "    config,\n",
    "    stream_mode=\"values\",\n",
    ")\n",
    "for event in events:\n",
    "    # Print the event details.\n",
    "    if \"messages\" in event:\n",
    "        event[\"messages\"][-1].pretty_print()\n",
    "\n",
    "# 11. Handle the pause. The graph is now waiting for the tool to complete.\n",
    "# Inspect the graph's state to get the prompt for the human.\n",
    "snapshot = graph.get_state(config)\n",
    "if snapshot.next: # `snapshot.next` shows that the 'tools' node is pending.\n",
    "    # Get the prompt for the human from the snapshot.\n",
    "    prompt_for_human = snapshot.values['messages'][-1].tool_calls[0]['args']['prompt_to_user']\n",
    "    \n",
    "    print(\"\\n--------------------------------------------------\")\n",
    "    print(f\"AI is waiting for your confirmation.\")\n",
    "    print(f\"AI Message: {prompt_for_human}\")\n",
    "    print(\"--------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "951adf29-4e23-4ad5-9cdd-a44c7f957f27",
   "metadata": {},
   "source": [
    " ## Resume Execution with Terminal Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d7f79f3-519a-4832-86fc-9feca211ac60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 12. Get confirmation from the user via the terminal.\n",
    "human_approval = \"\"\n",
    "while human_approval.lower().strip() != \"yes\":\n",
    "    human_approval = input(\"Please type 'yes' to continue: \")\n",
    "\n",
    "# 13. Resume the graph.\n",
    "# The `Command(resume={...})` object sends the human's input back to the paused tool.\n",
    "# One or more commands to update the graph's state and send messages to nodes.\n",
    "human_command = Command(resume={\"data\": human_approval})\n",
    "\n",
    "print(\"\\n--- User approved. Resuming execution... ---\")\n",
    "# The graph continues execution from where it left off.\n",
    "events = graph.stream(human_command, config, stream_mode=\"values\")\n",
    "for event in events:\n",
    "    # Print the event details.\n",
    "    if \"messages\" in event:\n",
    "        event[\"messages\"][-1].pretty_print()\n",
    "        \n",
    "print(\"\\n--- Run complete ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
