{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ca6c06ab",
   "metadata": {},
   "source": [
    "# Multi-Agent System\n",
    "## 1. Supervisor Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cbfd95c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Research Query Result:\n",
      "Research Agent: Based on my analysis of 'I need to research climate change impacts', here are the key findings: This topic involves complex data gathering and analysis.\n",
      "\n",
      "Math Query Result:\n",
      "Math Agent: Analyzing the mathematical aspects of 'Calculate the probability distribution': This involves numerical computation and statistical analysis.\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "549b50be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---CALLING RESEARCH AGENT---\n",
      "Researching: Could you research langgraph?\n",
      "{'research': HumanMessage(content='Found information on: Could you research langgraph?', additional_kwargs={}, response_metadata={}, id='a98c6008-d71b-47a5-993a-8de9eaaaddfd')}\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "What is 1 + 1?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/fk/vz88g8l931z47btqbn502kb00000gn/T/ipykernel_49469/2441313809.py:36: LangGraphDeprecatedSinceV10: MessageGraph is deprecated in LangGraph v1.0.0, to be removed in v2.0.0. Please use StateGraph with a `messages` key instead. Deprecated in LangGraph V1.0 to be removed in V2.0.\n",
      "  graph_builder = MessageGraph()\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from typing import Literal\n",
    "\n",
    "from langchain_core.messages import AnyMessage, HumanMessage\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.graph import END, MessageGraph\n",
    "from langgraph.prebuilt import ToolNode\n",
    "\n",
    "# This is a placeholder for a real tool; in a real app, you would use something like Tavily\n",
    "def research_tool(query: str):\n",
    "    print(f\"Researching: {query}\")\n",
    "    return f\"Found information on: {query}\"\n",
    "\n",
    "# Define the agents\n",
    "def research_agent(messages: list[AnyMessage]):\n",
    "    print(\"---CALLING RESEARCH AGENT---\")\n",
    "    # In a real app, you'd use an LLM to call the tool\n",
    "    # For this example, we'll just call it directly\n",
    "    result = research_tool(messages[-1].content)\n",
    "    return HumanMessage(content=result)\n",
    "\n",
    "def math_agent(messages: list[AnyMessage]):\n",
    "    print(\"---CALLING MATH AGENT---\")\n",
    "    return HumanMessage(content=\"The answer is 2.\")\n",
    "\n",
    "# The supervisor decides which agent to call next\n",
    "def supervisor(messages: list[AnyMessage]) -> Literal[\"research\", \"math\", END]:\n",
    "    last_message = messages[-1].content.lower()\n",
    "    if \"math\" in last_message:\n",
    "        return \"math\"\n",
    "    if \"research\" in last_message:\n",
    "        return \"research\"\n",
    "    return END\n",
    "\n",
    "# Build the graph\n",
    "graph_builder = MessageGraph()\n",
    "graph_builder.add_node(\"research\", research_agent)\n",
    "graph_builder.add_node(\"math\", math_agent)\n",
    "graph_builder.add_conditional_edges(\n",
    "    \"__start__\",\n",
    "    supervisor,\n",
    "    {\"research\": \"research\", \"math\": \"math\", END: END}\n",
    ")\n",
    "graph_builder.add_edge(\"research\", END)\n",
    "graph_builder.add_edge(\"math\", END)\n",
    "graph = graph_builder.compile(checkpointer=MemorySaver())\n",
    "\n",
    "# Run the graph\n",
    "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "for chunk in graph.stream([HumanMessage(content=\"Could you research langgraph?\")], config=config):\n",
    "    print(chunk)\n",
    "\n",
    "for chunk in graph.stream([HumanMessage(content=\"What is 1 + 1?\")], config=config, stream_mode=\"values\"):\n",
    "    chunk[-1].pretty_print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b2d62ba",
   "metadata": {},
   "source": [
    "#### Example 1: Supervisor Architecture (with ChatOllama)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "953401b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "What's the capital of Japan?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Tokyo.\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Compute 12*(3+4)\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "48\n"
     ]
    }
   ],
   "source": [
    "# pip install langgraph langchain langchain-ollama\n",
    "from langgraph.graph import StateGraph, START, END, MessagesState\n",
    "from langgraph.types import Command\n",
    "from langchain_core.messages import HumanMessage, AIMessage\n",
    "from langchain_ollama import ChatOllama, OllamaEmbeddings\n",
    "\n",
    "llm = ChatOllama(model='llama3.2')\n",
    "embedding = OllamaEmbeddings(model='nomic-embed-text')\n",
    "\n",
    "class State(MessagesState):\n",
    "    result: str\n",
    "\n",
    "def last_user(state: State) -> str:\n",
    "    for msg in reversed(state[\"messages\"]):\n",
    "        if getattr(msg, \"type\", getattr(msg, \"role\", \"\")) in (\"human\", \"user\"):\n",
    "            return msg.content if hasattr(msg, \"content\") else msg.get(\"content\",\"\")\n",
    "    return \"\"\n",
    "\n",
    "def supervisor(state: State):\n",
    "    if state.get(\"result\"): return Command(goto=\"finish\", update={})\n",
    "    q = last_user(state).lower()\n",
    "    if any(op in q for op in [\"+\", \"-\", \"*\", \"/\", \"solve\", \"calc\"]): return Command(goto=\"math\", update={})\n",
    "    return Command(goto=\"research\", update={})\n",
    "\n",
    "def research_agent(state: State):\n",
    "    q = last_user(state)\n",
    "    resp = llm.invoke([HumanMessage(content=f\"Answer briefly and factually: {q}\")])\n",
    "    return Command(goto=\"supervisor\", update={\"result\": resp.content})\n",
    "\n",
    "def math_agent(state: State):\n",
    "    q = last_user(state)\n",
    "    prompt = f\"Solve the math expression or question. Reply with the final answer only:\\n{q}\"\n",
    "    resp = llm.invoke([HumanMessage(content=prompt)])\n",
    "    return Command(goto=\"supervisor\", update={\"result\": resp.content.strip()})\n",
    "\n",
    "def finish(state: State):\n",
    "    return Command(goto=END, update={\"messages\": [AIMessage(content=state.get(\"result\",\"No result\"))]})\n",
    "\n",
    "builder = StateGraph(State)\n",
    "builder.add_node(\"supervisor\", supervisor)\n",
    "builder.add_node(\"research\", research_agent)\n",
    "builder.add_node(\"math\", math_agent)\n",
    "builder.add_node(\"finish\", finish)\n",
    "builder.add_edge(START, \"supervisor\")\n",
    "graph = builder.compile()\n",
    "\n",
    "out = graph.invoke({\"messages\": [HumanMessage(\"What's the capital of Japan?\")]})\n",
    "for m in out[\"messages\"]: m.pretty_print()\n",
    "out = graph.invoke({\"messages\": [HumanMessage(\"Compute 12*(3+4)\")]})\n",
    "for m in out[\"messages\"]: m.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd8b26eb",
   "metadata": {},
   "source": [
    "## 2. Network Architecture\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "47ac8bf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Network Collaboration Result:\n",
      "1. We need to develop a strategy for market expansion\n",
      "\n",
      "2. Analyst: I've reviewed 'We need to develop a strategy for market expansion'. The data suggests we need deeper investigation.\n",
      "\n",
      "3. Strategist: For 'Analyst: I've reviewed 'We need to develop a strategy for market expansion'. The data suggests we need deeper investigation.', I recommend a comprehensive approach combining multiple perspectives.\n",
      "\n",
      "4. Analyst: I've reviewed 'Strategist: For 'Analyst: I've reviewed 'We need to develop a strategy for market expansion'. The data suggests we need deeper investigation.', I recommend a comprehensive approach combining multiple perspectives.'. The data suggests we need deeper investigation.\n",
      "\n",
      "5. Strategist: Final recommendation compiled. All agents have contributed to the solution.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from typing import TypedDict, Literal\n",
    "from langgraph.graph import StateGraph, MessagesState\n",
    "from langchain_core.messages import HumanMessage, AIMessage\n",
    "from langgraph.types import Command\n",
    "\n",
    "# Define our state schema\n",
    "class NetworkState(MessagesState):\n",
    "    \"\"\"State for network of collaborating agents\"\"\"\n",
    "    iteration_count: int = 0\n",
    "\n",
    "# Network Agents - each can route to any other\n",
    "def analyst_agent(state: NetworkState) -> Command[Literal[\"researcher_agent\", \"strategist_agent\", \"__end__\"]]:\n",
    "    \"\"\"Analyst agent that processes data and routes accordingly\"\"\"\n",
    "    last_message = state[\"messages\"][-1].content\n",
    "    response = f\"Analyst: I've reviewed '{last_message}'. The data suggests we need deeper investigation.\"\n",
    "    \n",
    "    # Add response to state\n",
    "    new_state = {\n",
    "        \"messages\": [AIMessage(content=response)],\n",
    "        \"iteration_count\": state.get(\"iteration_count\", 0) + 1\n",
    "    }\n",
    "    \n",
    "    # Routing logic with iteration limit to prevent infinite loops\n",
    "    if state.get(\"iteration_count\", 0) >= 3:\n",
    "        return Command(goto=\"__end__\", update=new_state)\n",
    "    elif \"strategy\" in last_message.lower():\n",
    "        return Command(goto=\"strategist_agent\", update=new_state)\n",
    "    else:\n",
    "        return Command(goto=\"researcher_agent\", update=new_state)\n",
    "\n",
    "def researcher_agent(state: NetworkState) -> Command[Literal[\"analyst_agent\", \"strategist_agent\", \"__end__\"]]:\n",
    "    \"\"\"Researcher agent that gathers information\"\"\"\n",
    "    last_message = state[\"messages\"][-1].content\n",
    "    response = f\"Researcher: Based on my investigation of '{last_message}', I found relevant background information.\"\n",
    "    \n",
    "    new_state = {\n",
    "        \"messages\": [AIMessage(content=response)],\n",
    "        \"iteration_count\": state.get(\"iteration_count\", 0) + 1\n",
    "    }\n",
    "    \n",
    "    # Route based on content and iteration count\n",
    "    if state.get(\"iteration_count\", 0) >= 3:\n",
    "        return Command(goto=\"__end__\", update=new_state)\n",
    "    elif \"analysis\" in last_message.lower():\n",
    "        return Command(goto=\"analyst_agent\", update=new_state)\n",
    "    else:\n",
    "        return Command(goto=\"strategist_agent\", update=new_state)\n",
    "\n",
    "def strategist_agent(state: NetworkState) -> Command[Literal[\"analyst_agent\", \"researcher_agent\", \"__end__\"]]:\n",
    "    \"\"\"Strategist agent that develops plans\"\"\"\n",
    "    last_message = state[\"messages\"][-1].content\n",
    "    response = f\"Strategist: For '{last_message}', I recommend a comprehensive approach combining multiple perspectives.\"\n",
    "    \n",
    "    new_state = {\n",
    "        \"messages\": [AIMessage(content=response)],\n",
    "        \"iteration_count\": state.get(\"iteration_count\", 0) + 1\n",
    "    }\n",
    "    \n",
    "    # End the conversation after strategist provides final recommendation\n",
    "    if state.get(\"iteration_count\", 0) >= 2:\n",
    "        final_response = \"Strategist: Final recommendation compiled. All agents have contributed to the solution.\"\n",
    "        return Command(\n",
    "            goto=\"__end__\", \n",
    "            update={\"messages\": [AIMessage(content=final_response)]}\n",
    "        )\n",
    "    else:\n",
    "        return Command(goto=\"analyst_agent\", update=new_state)\n",
    "\n",
    "# Build the network graph\n",
    "def create_network_graph():\n",
    "    workflow = StateGraph(NetworkState)\n",
    "    \n",
    "    # Add all agent nodes\n",
    "    workflow.add_node(\"analyst_agent\", analyst_agent)\n",
    "    workflow.add_node(\"researcher_agent\", researcher_agent)\n",
    "    workflow.add_node(\"strategist_agent\", strategist_agent)\n",
    "    \n",
    "    # Set entry point (could be any agent)\n",
    "    workflow.set_entry_point(\"analyst_agent\")\n",
    "    \n",
    "    return workflow.compile()\n",
    "\n",
    "# Usage example\n",
    "if __name__ == \"__main__\":\n",
    "    graph = create_network_graph()\n",
    "    \n",
    "    # Test network collaboration\n",
    "    result = graph.invoke({\n",
    "        \"messages\": [HumanMessage(content=\"We need to develop a strategy for market expansion\")],\n",
    "        \"iteration_count\": 0\n",
    "    })\n",
    "    \n",
    "    print(\"Network Collaboration Result:\")\n",
    "    for i, message in enumerate(result[\"messages\"]):\n",
    "        print(f\"{i+1}. {message.content}\")\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07884c62",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c2109aea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Discuss pros/cons of remote work.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "As a seasoned intelligence operative like myself, I can attest that the shift to remote work has its advantages, such as increased flexibility and reduced commuting time, but also presents challenges, including potential isolation and blurred boundaries between personal and professional life.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Remote work offers a flexible and autonomous work environment that boosts productivity, reduces commuting time and expenses, but also raises concerns about isolation, blurring boundaries between work and personal life, and potential loss of social interactions and face-to-face collaboration opportunities.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "\"As Agent Gamma, I've analyzed the situation and concluded that while remote work offers benefits such as increased flexibility and reduced commuting time, it also presents drawbacks like decreased social interaction and potential distractions at home, making it essential to weigh these pros and cons carefully to determine whether remote work is the right fit for individual circumstances.\"\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "As Agent Alpha, I've analyzed the data and found that while remote work offers increased flexibility and autonomy, it also raises concerns about social isolation, communication breakdowns, and difficulty separating work and personal life.\n",
      "\n",
      "Here is a list of pros and cons:\n",
      "\n",
      "**Pros:**\n",
      "\n",
      "1. Increased flexibility and autonomy\n",
      "2. Reduced commuting time and expenses\n",
      "3. Improved work-life balance\n",
      "4. Broader talent pool and reduced recruitment costs\n",
      "5. Enhanced productivity due to fewer office distractions\n",
      "\n",
      "**Cons:**\n",
      "\n",
      "1. Social isolation and loneliness\n",
      "2. Difficulty in building strong relationships with colleagues and supervisors\n",
      "3. Communication breakdowns due to lack of face-to-face interaction\n",
      "4. Blurred boundaries between work and personal life\n",
      "5. Technical issues and cybersecurity risks\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Consensus reached. Done.\n"
     ]
    }
   ],
   "source": [
    "# pip install langgraph langchain langchain-ollama\n",
    "from langgraph.graph import StateGraph, START, END, MessagesState\n",
    "from langgraph.types import Command\n",
    "from langchain_core.messages import HumanMessage, AIMessage\n",
    "from langchain_ollama import ChatOllama, OllamaEmbeddings\n",
    "\n",
    "llm = ChatOllama(model='llama3.2')\n",
    "embedding = OllamaEmbeddings(model='nomic-embed-text')\n",
    "\n",
    "class NetState(MessagesState):\n",
    "    turns: int\n",
    "\n",
    "MAX_TURNS = 4\n",
    "\n",
    "def last_user(state: NetState) -> str:\n",
    "    for msg in reversed(state[\"messages\"]):\n",
    "        if getattr(msg, \"type\", getattr(msg, \"role\",\"\")) in (\"human\",\"user\"):\n",
    "            return msg.content if hasattr(msg, \"content\") else msg.get(\"content\",\"\")\n",
    "    return \"\"\n",
    "\n",
    "def stop(state: NetState) -> bool:\n",
    "    if state.get(\"turns\",0) >= MAX_TURNS: return True\n",
    "    last = state[\"messages\"][-1]; txt = getattr(last,\"content\", \"\")\n",
    "    return \"stop\" in str(txt).lower()\n",
    "\n",
    "def alpha(state: NetState):\n",
    "    t = state.get(\"turns\",0)+1\n",
    "    topic = last_user(state)\n",
    "    resp = llm.invoke([HumanMessage(content=f\"As agent alpha, add one sentence about: {topic}\")])\n",
    "    upd = {\"messages\":[AIMessage(content=resp.content)], \"turns\": t}\n",
    "    return Command(goto=\"end\" if stop({**state,**upd}) else \"beta\", update=upd)\n",
    "\n",
    "def beta(state: NetState):\n",
    "    t = state.get(\"turns\",0)+1\n",
    "    topic = last_user(state)\n",
    "    resp = llm.invoke([HumanMessage(content=f\"As agent beta, refine in one sentence: {topic}\")])\n",
    "    upd = {\"messages\":[AIMessage(content=resp.content)], \"turns\": t}\n",
    "    return Command(goto=\"end\" if stop({**state,**upd}) else \"gamma\", update=upd)\n",
    "\n",
    "def gamma(state: NetState):\n",
    "    t = state.get(\"turns\",0)+1\n",
    "    topic = last_user(state)\n",
    "    resp = llm.invoke([HumanMessage(content=f\"As agent gamma, propose a conclusion in one sentence about: {topic}\")])\n",
    "    upd = {\"messages\":[AIMessage(content=resp.content)], \"turns\": t}\n",
    "    return Command(goto=\"end\" if stop({**state,**upd}) else \"alpha\", update=upd)\n",
    "\n",
    "def end_node(state: NetState):\n",
    "    return Command(goto=END, update={\"messages\":[AIMessage(content=\"Consensus reached. Done.\")]})\n",
    "\n",
    "builder = StateGraph(NetState)\n",
    "builder.add_node(\"alpha\", alpha)\n",
    "builder.add_node(\"beta\", beta)\n",
    "builder.add_node(\"gamma\", gamma)\n",
    "builder.add_node(\"end\", end_node)\n",
    "builder.add_edge(START, \"alpha\")\n",
    "graph = builder.compile()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    init = {\"messages\":[HumanMessage(\"Discuss pros/cons of remote work.\")], \"turns\":0}\n",
    "    out = graph.invoke(init)\n",
    "    for m in out[\"messages\"]: m.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9c14314",
   "metadata": {},
   "source": [
    "## 3. Hierarchical Architecture\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3407b77e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated, Any, Literal\n",
    "\n",
    "from langchain_core.messages import AnyMessage, HumanMessage, ToolMessage\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.graph import END, MessageGraph\n",
    "\n",
    "# Define teams as subgraphs\n",
    "def research_node(messages: list[AnyMessage]):\n",
    "    print(\"---CALLING RESEARCH TEAM---\")\n",
    "    # In a real app, this would be a more complex graph\n",
    "    return HumanMessage(content=\"LangGraph is a framework for building stateful, multi-agent applications.\")\n",
    "\n",
    "def analysis_node(messages: list[AnyMessage]):\n",
    "    print(\"---CALLING ANALYSIS TEAM---\")\n",
    "    # This team \"analyzes\" the research output\n",
    "    return HumanMessage(content=f\"Analysis complete. Summary: {messages[-1].content}\")\n",
    "\n",
    "research_team = MessageGraph()\n",
    "research_team.add_node(\"researcher\", research_node)\n",
    "research_team.add_edge(\"researcher\", END)\n",
    "research_graph = research_team.compile()\n",
    "\n",
    "analysis_team = MessageGraph()\n",
    "analysis_team.add_node(\"analyzer\", analysis_node)\n",
    "analysis_team.add_edge(\"analyzer\", END)\n",
    "analysis_graph = analysis_team.compile()\n",
    "\n",
    "# Top-level supervisor routes to the appropriate team\n",
    "def top_supervisor(messages: list[AnyMessage]) -> Literal[\"research_team\", \"analysis_team\", END]:\n",
    "    last_message = messages[-1]\n",
    "    if \"research\" in last_message.content.lower():\n",
    "        return \"research_team\"\n",
    "    # If the last message came from the research team, pass to analysis\n",
    "    if isinstance(last_message, HumanMessage) and \"LangGraph is a framework\" in last_message.content:\n",
    "        return \"analysis_team\"\n",
    "    return END\n",
    "\n",
    "# Build the final graph by composing the subgraphs\n",
    "graph_builder = MessageGraph()\n",
    "graph_builder.add_node(\"research_team\", research_graph)\n",
    "graph_builder.add_node(\"analysis_team\", analysis_graph)\n",
    "graph_builder.add_conditional_edges(\"__start__\", top_supervisor)\n",
    "graph_builder.add_conditional_edges(\"research_team\", top_supervisor)\n",
    "graph_builder.add_edge(\"analysis_team\", END)\n",
    "graph = graph_builder.compile(checkpointer=MemorySaver())\n",
    "\n",
    "# Run the full hierarchy\n",
    "config = {\"configurable\": {\"thread_id\": \"3\"}}\n",
    "initial_message = [HumanMessage(content=\"Can you research LangGraph and then analyze the result?\")]\n",
    "for chunk in graph.stream(initial_message, config=config):\n",
    "    print(chunk)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "85b6cec9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Who created Python?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Guido van Rossum.\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Quickly estimate 20*(5-2).\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "A score of 0 should be given for the estimate because the original problem requires a precise calculation and does not allow for approximations or rough estimates.\n"
     ]
    }
   ],
   "source": [
    "# pip install langgraph langchain langchain-ollama\n",
    "from langgraph.graph import StateGraph, START, END, MessagesState\n",
    "from langgraph.types import Command\n",
    "from langchain_core.messages import HumanMessage, AIMessage\n",
    "from langchain_ollama import ChatOllama, OllamaEmbeddings\n",
    "\n",
    "llm = ChatOllama(model='llama3.2')\n",
    "embedding = OllamaEmbeddings(model='nomic-embed-text')\n",
    "\n",
    "class TopState(MessagesState):\n",
    "    data: str\n",
    "    notes: str\n",
    "\n",
    "def last_user(s: TopState) -> str:\n",
    "    for m in reversed(s[\"messages\"]):\n",
    "        if getattr(m,\"type\", getattr(m,\"role\",\"\")) in (\"human\",\"user\"):\n",
    "            return m.content if hasattr(m,\"content\") else m.get(\"content\",\"\")\n",
    "    return \"\"\n",
    "\n",
    "DOCS = [\n",
    "    \"Python was created by Guido van Rossum.\",\n",
    "    \"The capital of Japan is Tokyo.\",\n",
    "    \"LangGraph helps build multi-agent workflows.\",\n",
    "]\n",
    "V_DOCS = [embedding.embed_query(d) for d in DOCS]\n",
    "\n",
    "def gather(state: TopState):\n",
    "    q = last_user(state); qv = embedding.embed_query(q)\n",
    "    idx = max(range(len(DOCS)), key=lambda i: sum(a*b for a,b in zip(V_DOCS[i], qv)))\n",
    "    return {\"data\": DOCS[idx]}\n",
    "\n",
    "def synthesize(state: TopState):\n",
    "    prompt = f\"Using this note, answer the user briefly:\\nNote: {state.get('data','')}\\nUser: {last_user(state)}\"\n",
    "    resp = llm.invoke([HumanMessage(content=prompt)])\n",
    "    return {\"notes\": resp.content}\n",
    "\n",
    "def compute(state: TopState):\n",
    "    q = last_user(state)\n",
    "    resp = llm.invoke([HumanMessage(content=f\"Analyze and give a score 0-1 with a reason for: {q}\")])\n",
    "    return {\"data\": resp.content}\n",
    "\n",
    "def summarize(state: TopState):\n",
    "    resp = llm.invoke([HumanMessage(content=f\"Summarize to one sentence: {state.get('data','')}\")])\n",
    "    return {\"notes\": resp.content}\n",
    "\n",
    "# Research subgraph\n",
    "r = StateGraph(TopState); r.add_node(\"gather\", gather); r.add_node(\"synth\", synthesize)\n",
    "r.add_edge(START,\"gather\"); r.add_edge(\"gather\",\"synth\"); r.add_edge(\"synth\", END)\n",
    "research_team = r.compile()\n",
    "\n",
    "# Analysis subgraph\n",
    "a = StateGraph(TopState); a.add_node(\"compute\", compute); a.add_node(\"summary\", summarize)\n",
    "a.add_edge(START,\"compute\"); a.add_edge(\"compute\",\"summary\"); a.add_edge(\"summary\", END)\n",
    "analysis_team = a.compile()\n",
    "\n",
    "def supervisor(state: TopState):\n",
    "    q = last_user(state).lower()\n",
    "    if state.get(\"notes\"): return Command(goto=\"final\", update={})\n",
    "    if any(op in q for op in [\"+\", \"-\", \"*\", \"/\", \"calc\",\"solve\"]): return Command(goto=\"analysis_team\", update={})\n",
    "    return Command(goto=\"research_team\", update={})\n",
    "\n",
    "def final_node(state: TopState):\n",
    "    return Command(goto=END, update={\"messages\":[AIMessage(content=state.get(\"notes\",\"No notes\"))]})\n",
    "\n",
    "b = StateGraph(TopState)\n",
    "b.add_node(\"supervisor\", supervisor)\n",
    "b.add_node(\"research_team\", research_team)\n",
    "b.add_node(\"analysis_team\", analysis_team)\n",
    "b.add_node(\"final\", final_node)\n",
    "b.add_edge(START,\"supervisor\")\n",
    "b.add_edge(\"research_team\",\"final\"); b.add_edge(\"analysis_team\",\"final\")\n",
    "graph = b.compile()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    out = graph.invoke({\"messages\":[HumanMessage(\"Who created Python?\")]})\n",
    "    for m in out[\"messages\"]: m.pretty_print()\n",
    "    out = graph.invoke({\"messages\":[HumanMessage(\"Quickly estimate 20*(5-2).\")]})\n",
    "    for m in out[\"messages\"]: m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cb358a39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Research Task Result:\n",
      "- We need to gather information about customer preferences\n",
      "- Research Supervisor: Coordinating data collection and analysis.\n",
      "- Data Collector: Gathered comprehensive data on 'Research Supervisor: Coordinating data collection and analysis.'\n",
      "\n",
      "Analysis Task Result:\n",
      "- Analyze the sales data trends\n",
      "- Analysis Supervisor: Initiating data analysis workflow.\n",
      "- Data Analyst: Completed statistical analysis of 'Analysis Supervisor: Initiating data analysis workflow.'\n"
     ]
    }
   ],
   "source": [
    "from typing import TypedDict, Literal\n",
    "from langgraph.graph import StateGraph, MessagesState\n",
    "from langchain_core.messages import HumanMessage, AIMessage\n",
    "from langgraph.types import Command\n",
    "\n",
    "# Define our state schema\n",
    "class HierarchicalState(MessagesState):\n",
    "    \"\"\"State for hierarchical agent system\"\"\"\n",
    "    team_assigned: str = \"\"\n",
    "\n",
    "# Research Team Agents\n",
    "def data_collector(state: HierarchicalState) -> HierarchicalState:\n",
    "    \"\"\"Collects data for research team\"\"\"\n",
    "    last_message = state[\"messages\"][-1].content\n",
    "    response = f\"Data Collector: Gathered comprehensive data on '{last_message}'\"\n",
    "    return {\"messages\": [AIMessage(content=response)]}\n",
    "\n",
    "def research_supervisor(state: HierarchicalState) -> Command[Literal[\"data_collector\", \"__end__\"]]:\n",
    "    \"\"\"Supervises research team\"\"\"\n",
    "    response = \"Research Supervisor: Coordinating data collection and analysis.\"\n",
    "    return Command(\n",
    "        goto=\"data_collector\",\n",
    "        update={\"messages\": [AIMessage(content=response)]}\n",
    "    )\n",
    "\n",
    "# Analysis Team Agents  \n",
    "def data_analyst(state: HierarchicalState) -> HierarchicalState:\n",
    "    \"\"\"Analyzes data for analysis team\"\"\"\n",
    "    last_message = state[\"messages\"][-1].content\n",
    "    response = f\"Data Analyst: Completed statistical analysis of '{last_message}'\"\n",
    "    return {\"messages\": [AIMessage(content=response)]}\n",
    "\n",
    "def analysis_supervisor(state: HierarchicalState) -> Command[Literal[\"data_analyst\", \"__end__\"]]:\n",
    "    \"\"\"Supervises analysis team\"\"\"\n",
    "    response = \"Analysis Supervisor: Initiating data analysis workflow.\"\n",
    "    return Command(\n",
    "        goto=\"data_analyst\",\n",
    "        update={\"messages\": [AIMessage(content=response)]}\n",
    "    )\n",
    "\n",
    "# Top-level supervisor\n",
    "def top_supervisor(state: HierarchicalState) -> Command[Literal[\"research_team\", \"analysis_team\", \"__end__\"]]:\n",
    "    \"\"\"Top-level supervisor that routes to appropriate teams\"\"\"\n",
    "    last_message = state[\"messages\"][-1].content.lower()\n",
    "    \n",
    "    if any(word in last_message for word in [\"collect\", \"gather\", \"research\", \"find\"]):\n",
    "        return Command(\n",
    "            goto=\"research_team\",\n",
    "            update={\"team_assigned\": \"research\"}\n",
    "        )\n",
    "    elif any(word in last_message for word in [\"analyze\", \"calculate\", \"process\", \"examine\"]):\n",
    "        return Command(\n",
    "            goto=\"analysis_team\", \n",
    "            update={\"team_assigned\": \"analysis\"}\n",
    "        )\n",
    "    else:\n",
    "        # Default to research team\n",
    "        return Command(\n",
    "            goto=\"research_team\",\n",
    "            update={\"team_assigned\": \"research\"}\n",
    "        )\n",
    "\n",
    "# Create subgraphs for teams\n",
    "def create_research_team():\n",
    "    \"\"\"Create research team subgraph\"\"\"\n",
    "    team_workflow = StateGraph(HierarchicalState)\n",
    "    team_workflow.add_node(\"research_supervisor\", research_supervisor)\n",
    "    team_workflow.add_node(\"data_collector\", data_collector)\n",
    "    team_workflow.add_edge(\"data_collector\", \"__end__\")\n",
    "    team_workflow.set_entry_point(\"research_supervisor\")\n",
    "    return team_workflow.compile()\n",
    "\n",
    "def create_analysis_team():\n",
    "    \"\"\"Create analysis team subgraph\"\"\"\n",
    "    team_workflow = StateGraph(HierarchicalState)\n",
    "    team_workflow.add_node(\"analysis_supervisor\", analysis_supervisor)\n",
    "    team_workflow.add_node(\"data_analyst\", data_analyst)\n",
    "    team_workflow.add_edge(\"data_analyst\", \"__end__\")\n",
    "    team_workflow.set_entry_point(\"analysis_supervisor\")\n",
    "    return team_workflow.compile()\n",
    "\n",
    "# Build the main hierarchical graph\n",
    "def create_hierarchical_graph():\n",
    "    workflow = StateGraph(HierarchicalState)\n",
    "    \n",
    "    # Add top supervisor\n",
    "    workflow.add_node(\"top_supervisor\", top_supervisor)\n",
    "    \n",
    "    # Add team subgraphs\n",
    "    workflow.add_node(\"research_team\", create_research_team())\n",
    "    workflow.add_node(\"analysis_team\", create_analysis_team())\n",
    "    \n",
    "    # Connect teams back to end\n",
    "    workflow.add_edge(\"research_team\", \"__end__\")\n",
    "    workflow.add_edge(\"analysis_team\", \"__end__\")\n",
    "    \n",
    "    # Set entry point\n",
    "    workflow.set_entry_point(\"top_supervisor\")\n",
    "    \n",
    "    return workflow.compile()\n",
    "\n",
    "# Usage example\n",
    "if __name__ == \"__main__\":\n",
    "    graph = create_hierarchical_graph()\n",
    "    \n",
    "    # Test with research task\n",
    "    result1 = graph.invoke({\n",
    "        \"messages\": [HumanMessage(content=\"We need to gather information about customer preferences\")]\n",
    "    })\n",
    "    print(\"Research Task Result:\")\n",
    "    for message in result1[\"messages\"]:\n",
    "        print(f\"- {message.content}\")\n",
    "    print()\n",
    "    \n",
    "    # Test with analysis task\n",
    "    result2 = graph.invoke({\n",
    "        \"messages\": [HumanMessage(content=\"Analyze the sales data trends\")]\n",
    "    })\n",
    "    print(\"Analysis Task Result:\")\n",
    "    for message in result2[\"messages\"]:\n",
    "        print(f\"- {message.content}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f5ad35e",
   "metadata": {},
   "source": [
    "## CC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "25243351",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Research Query Result:\n",
      "Research Agent: Based on my analysis of 'I need to research climate change impacts', here are the key findings: This topic involves complex data gathering and analysis.\n",
      "\n",
      "Math Query Result:\n",
      "Math Agent: Analyzing the mathematical aspects of 'Calculate the probability distribution': This involves numerical computation and statistical analysis.\n"
     ]
    }
   ],
   "source": [
    "from typing import TypedDict, Literal\n",
    "from langgraph.graph import StateGraph, MessagesState\n",
    "from langgraph.graph.message import add_messages\n",
    "from langchain_core.messages import HumanMessage, AIMessage\n",
    "from langgraph.types import Command\n",
    "\n",
    "# Define our state schema\n",
    "class SupervisorState(MessagesState):\n",
    "    \"\"\"State that includes messages and any additional context\"\"\"\n",
    "    pass\n",
    "\n",
    "# Worker Agents\n",
    "def research_agent(state: SupervisorState) -> SupervisorState:\n",
    "    \"\"\"Handles research-related queries\"\"\"\n",
    "    last_message = state[\"messages\"][-1].content\n",
    "    response = f\"Research Agent: Based on my analysis of '{last_message}', here are the key findings: This topic involves complex data gathering and analysis.\"\n",
    "    \n",
    "    return {\n",
    "        \"messages\": [AIMessage(content=response)]\n",
    "    }\n",
    "\n",
    "def math_agent(state: SupervisorState) -> SupervisorState:\n",
    "    \"\"\"Handles mathematical calculations\"\"\"\n",
    "    last_message = state[\"messages\"][-1].content\n",
    "    response = f\"Math Agent: Analyzing the mathematical aspects of '{last_message}': This involves numerical computation and statistical analysis.\"\n",
    "    \n",
    "    return {\n",
    "        \"messages\": [AIMessage(content=response)]\n",
    "    }\n",
    "\n",
    "def supervisor_agent(state: SupervisorState) -> Command[Literal[\"research_agent\", \"math_agent\", \"__end__\"]]:\n",
    "    \"\"\"Central supervisor that routes to appropriate worker agents\"\"\"\n",
    "    last_message = state[\"messages\"][-1].content.lower()\n",
    "    \n",
    "    # Simple routing logic based on keywords\n",
    "    if any(word in last_message for word in [\"research\", \"study\", \"analyze\", \"investigate\"]):\n",
    "        return Command(goto=\"research_agent\")\n",
    "    elif any(word in last_message for word in [\"calculate\", \"math\", \"number\", \"formula\"]):\n",
    "        return Command(goto=\"math_agent\")\n",
    "    else:\n",
    "        # Default to research for ambiguous queries\n",
    "        return Command(goto=\"research_agent\")\n",
    "\n",
    "# Build the graph\n",
    "def create_supervisor_graph():\n",
    "    workflow = StateGraph(SupervisorState)\n",
    "    \n",
    "    # Add nodes\n",
    "    workflow.add_node(\"supervisor\", supervisor_agent)\n",
    "    workflow.add_node(\"research_agent\", research_agent)\n",
    "    workflow.add_node(\"math_agent\", math_agent)\n",
    "    \n",
    "    # Define edges\n",
    "    workflow.add_edge(\"research_agent\", \"__end__\")\n",
    "    workflow.add_edge(\"math_agent\", \"__end__\")\n",
    "    \n",
    "    # Set entry point\n",
    "    workflow.set_entry_point(\"supervisor\")\n",
    "    \n",
    "    return workflow.compile()\n",
    "\n",
    "# Usage example\n",
    "if __name__ == \"__main__\":\n",
    "    graph = create_supervisor_graph()\n",
    "    \n",
    "    # Test with research query\n",
    "    result1 = graph.invoke({\n",
    "        \"messages\": [HumanMessage(content=\"I need to research climate change impacts\")]\n",
    "    })\n",
    "    print(\"Research Query Result:\")\n",
    "    print(result1[\"messages\"][-1].content)\n",
    "    print()\n",
    "    \n",
    "    # Test with math query\n",
    "    result2 = graph.invoke({\n",
    "        \"messages\": [HumanMessage(content=\"Calculate the probability distribution\")]\n",
    "    })\n",
    "    print(\"Math Query Result:\")\n",
    "    print(result2[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9f6eddba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Network Collaboration Result:\n",
      "1. We need to develop a strategy for market expansion\n",
      "\n",
      "2. Analyst: I've reviewed 'We need to develop a strategy for market expansion'. The data suggests we need deeper investigation.\n",
      "\n",
      "3. Strategist: For 'Analyst: I've reviewed 'We need to develop a strategy for market expansion'. The data suggests we need deeper investigation.', I recommend a comprehensive approach combining multiple perspectives.\n",
      "\n",
      "4. Analyst: I've reviewed 'Strategist: For 'Analyst: I've reviewed 'We need to develop a strategy for market expansion'. The data suggests we need deeper investigation.', I recommend a comprehensive approach combining multiple perspectives.'. The data suggests we need deeper investigation.\n",
      "\n",
      "5. Strategist: Final recommendation compiled. All agents have contributed to the solution.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from typing import TypedDict, Literal\n",
    "from langgraph.graph import StateGraph, MessagesState\n",
    "from langchain_core.messages import HumanMessage, AIMessage\n",
    "from langgraph.types import Command\n",
    "\n",
    "# Define our state schema\n",
    "class NetworkState(MessagesState):\n",
    "    \"\"\"State for network of collaborating agents\"\"\"\n",
    "    iteration_count: int = 0\n",
    "\n",
    "# Network Agents - each can route to any other\n",
    "def analyst_agent(state: NetworkState) -> Command[Literal[\"researcher_agent\", \"strategist_agent\", \"__end__\"]]:\n",
    "    \"\"\"Analyst agent that processes data and routes accordingly\"\"\"\n",
    "    last_message = state[\"messages\"][-1].content\n",
    "    response = f\"Analyst: I've reviewed '{last_message}'. The data suggests we need deeper investigation.\"\n",
    "    \n",
    "    # Add response to state\n",
    "    new_state = {\n",
    "        \"messages\": [AIMessage(content=response)],\n",
    "        \"iteration_count\": state.get(\"iteration_count\", 0) + 1\n",
    "    }\n",
    "    \n",
    "    # Routing logic with iteration limit to prevent infinite loops\n",
    "    if state.get(\"iteration_count\", 0) >= 3:\n",
    "        return Command(goto=\"__end__\", update=new_state)\n",
    "    elif \"strategy\" in last_message.lower():\n",
    "        return Command(goto=\"strategist_agent\", update=new_state)\n",
    "    else:\n",
    "        return Command(goto=\"researcher_agent\", update=new_state)\n",
    "\n",
    "def researcher_agent(state: NetworkState) -> Command[Literal[\"analyst_agent\", \"strategist_agent\", \"__end__\"]]:\n",
    "    \"\"\"Researcher agent that gathers information\"\"\"\n",
    "    last_message = state[\"messages\"][-1].content\n",
    "    response = f\"Researcher: Based on my investigation of '{last_message}', I found relevant background information.\"\n",
    "    \n",
    "    new_state = {\n",
    "        \"messages\": [AIMessage(content=response)],\n",
    "        \"iteration_count\": state.get(\"iteration_count\", 0) + 1\n",
    "    }\n",
    "    \n",
    "    # Route based on content and iteration count\n",
    "    if state.get(\"iteration_count\", 0) >= 3:\n",
    "        return Command(goto=\"__end__\", update=new_state)\n",
    "    elif \"analysis\" in last_message.lower():\n",
    "        return Command(goto=\"analyst_agent\", update=new_state)\n",
    "    else:\n",
    "        return Command(goto=\"strategist_agent\", update=new_state)\n",
    "\n",
    "def strategist_agent(state: NetworkState) -> Command[Literal[\"analyst_agent\", \"researcher_agent\", \"__end__\"]]:\n",
    "    \"\"\"Strategist agent that develops plans\"\"\"\n",
    "    last_message = state[\"messages\"][-1].content\n",
    "    response = f\"Strategist: For '{last_message}', I recommend a comprehensive approach combining multiple perspectives.\"\n",
    "    \n",
    "    new_state = {\n",
    "        \"messages\": [AIMessage(content=response)],\n",
    "        \"iteration_count\": state.get(\"iteration_count\", 0) + 1\n",
    "    }\n",
    "    \n",
    "    # End the conversation after strategist provides final recommendation\n",
    "    if state.get(\"iteration_count\", 0) >= 2:\n",
    "        final_response = \"Strategist: Final recommendation compiled. All agents have contributed to the solution.\"\n",
    "        return Command(\n",
    "            goto=\"__end__\", \n",
    "            update={\"messages\": [AIMessage(content=final_response)]}\n",
    "        )\n",
    "    else:\n",
    "        return Command(goto=\"analyst_agent\", update=new_state)\n",
    "\n",
    "# Build the network graph\n",
    "def create_network_graph():\n",
    "    workflow = StateGraph(NetworkState)\n",
    "    \n",
    "    # Add all agent nodes\n",
    "    workflow.add_node(\"analyst_agent\", analyst_agent)\n",
    "    workflow.add_node(\"researcher_agent\", researcher_agent)\n",
    "    workflow.add_node(\"strategist_agent\", strategist_agent)\n",
    "    \n",
    "    # Set entry point (could be any agent)\n",
    "    workflow.set_entry_point(\"analyst_agent\")\n",
    "    \n",
    "    return workflow.compile()\n",
    "\n",
    "# Usage example\n",
    "if __name__ == \"__main__\":\n",
    "    graph = create_network_graph()\n",
    "    \n",
    "    # Test network collaboration\n",
    "    result = graph.invoke({\n",
    "        \"messages\": [HumanMessage(content=\"We need to develop a strategy for market expansion\")],\n",
    "        \"iteration_count\": 0\n",
    "    })\n",
    "    \n",
    "    print(\"Network Collaboration Result:\")\n",
    "    for i, message in enumerate(result[\"messages\"]):\n",
    "        print(f\"{i+1}. {message.content}\")\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "413ba637",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Research Task Result:\n",
      "- We need to gather information about customer preferences\n",
      "- Research Supervisor: Coordinating data collection and analysis.\n",
      "- Data Collector: Gathered comprehensive data on 'Research Supervisor: Coordinating data collection and analysis.'\n",
      "\n",
      "Analysis Task Result:\n",
      "- Analyze the sales data trends\n",
      "- Analysis Supervisor: Initiating data analysis workflow.\n",
      "- Data Analyst: Completed statistical analysis of 'Analysis Supervisor: Initiating data analysis workflow.'\n"
     ]
    }
   ],
   "source": [
    "from typing import TypedDict, Literal\n",
    "from langgraph.graph import StateGraph, MessagesState\n",
    "from langchain_core.messages import HumanMessage, AIMessage\n",
    "from langgraph.types import Command\n",
    "\n",
    "# Define our state schema\n",
    "class HierarchicalState(MessagesState):\n",
    "    \"\"\"State for hierarchical agent system\"\"\"\n",
    "    team_assigned: str = \"\"\n",
    "\n",
    "# Research Team Agents\n",
    "def data_collector(state: HierarchicalState) -> HierarchicalState:\n",
    "    \"\"\"Collects data for research team\"\"\"\n",
    "    last_message = state[\"messages\"][-1].content\n",
    "    response = f\"Data Collector: Gathered comprehensive data on '{last_message}'\"\n",
    "    return {\"messages\": [AIMessage(content=response)]}\n",
    "\n",
    "def research_supervisor(state: HierarchicalState) -> Command[Literal[\"data_collector\", \"__end__\"]]:\n",
    "    \"\"\"Supervises research team\"\"\"\n",
    "    response = \"Research Supervisor: Coordinating data collection and analysis.\"\n",
    "    return Command(\n",
    "        goto=\"data_collector\",\n",
    "        update={\"messages\": [AIMessage(content=response)]}\n",
    "    )\n",
    "\n",
    "# Analysis Team Agents  \n",
    "def data_analyst(state: HierarchicalState) -> HierarchicalState:\n",
    "    \"\"\"Analyzes data for analysis team\"\"\"\n",
    "    last_message = state[\"messages\"][-1].content\n",
    "    response = f\"Data Analyst: Completed statistical analysis of '{last_message}'\"\n",
    "    return {\"messages\": [AIMessage(content=response)]}\n",
    "\n",
    "def analysis_supervisor(state: HierarchicalState) -> Command[Literal[\"data_analyst\", \"__end__\"]]:\n",
    "    \"\"\"Supervises analysis team\"\"\"\n",
    "    response = \"Analysis Supervisor: Initiating data analysis workflow.\"\n",
    "    return Command(\n",
    "        goto=\"data_analyst\",\n",
    "        update={\"messages\": [AIMessage(content=response)]}\n",
    "    )\n",
    "\n",
    "# Top-level supervisor\n",
    "def top_supervisor(state: HierarchicalState) -> Command[Literal[\"research_team\", \"analysis_team\", \"__end__\"]]:\n",
    "    \"\"\"Top-level supervisor that routes to appropriate teams\"\"\"\n",
    "    last_message = state[\"messages\"][-1].content.lower()\n",
    "    \n",
    "    if any(word in last_message for word in [\"collect\", \"gather\", \"research\", \"find\"]):\n",
    "        return Command(\n",
    "            goto=\"research_team\",\n",
    "            update={\"team_assigned\": \"research\"}\n",
    "        )\n",
    "    elif any(word in last_message for word in [\"analyze\", \"calculate\", \"process\", \"examine\"]):\n",
    "        return Command(\n",
    "            goto=\"analysis_team\", \n",
    "            update={\"team_assigned\": \"analysis\"}\n",
    "        )\n",
    "    else:\n",
    "        # Default to research team\n",
    "        return Command(\n",
    "            goto=\"research_team\",\n",
    "            update={\"team_assigned\": \"research\"}\n",
    "        )\n",
    "\n",
    "# Create subgraphs for teams\n",
    "def create_research_team():\n",
    "    \"\"\"Create research team subgraph\"\"\"\n",
    "    team_workflow = StateGraph(HierarchicalState)\n",
    "    team_workflow.add_node(\"research_supervisor\", research_supervisor)\n",
    "    team_workflow.add_node(\"data_collector\", data_collector)\n",
    "    team_workflow.add_edge(\"data_collector\", \"__end__\")\n",
    "    team_workflow.set_entry_point(\"research_supervisor\")\n",
    "    return team_workflow.compile()\n",
    "\n",
    "def create_analysis_team():\n",
    "    \"\"\"Create analysis team subgraph\"\"\"\n",
    "    team_workflow = StateGraph(HierarchicalState)\n",
    "    team_workflow.add_node(\"analysis_supervisor\", analysis_supervisor)\n",
    "    team_workflow.add_node(\"data_analyst\", data_analyst)\n",
    "    team_workflow.add_edge(\"data_analyst\", \"__end__\")\n",
    "    team_workflow.set_entry_point(\"analysis_supervisor\")\n",
    "    return team_workflow.compile()\n",
    "\n",
    "# Build the main hierarchical graph\n",
    "def create_hierarchical_graph():\n",
    "    workflow = StateGraph(HierarchicalState)\n",
    "    \n",
    "    # Add top supervisor\n",
    "    workflow.add_node(\"top_supervisor\", top_supervisor)\n",
    "    \n",
    "    # Add team subgraphs\n",
    "    workflow.add_node(\"research_team\", create_research_team())\n",
    "    workflow.add_node(\"analysis_team\", create_analysis_team())\n",
    "    \n",
    "    # Connect teams back to end\n",
    "    workflow.add_edge(\"research_team\", \"__end__\")\n",
    "    workflow.add_edge(\"analysis_team\", \"__end__\")\n",
    "    \n",
    "    # Set entry point\n",
    "    workflow.set_entry_point(\"top_supervisor\")\n",
    "    \n",
    "    return workflow.compile()\n",
    "\n",
    "# Usage example\n",
    "if __name__ == \"__main__\":\n",
    "    graph = create_hierarchical_graph()\n",
    "    \n",
    "    # Test with research task\n",
    "    result1 = graph.invoke({\n",
    "        \"messages\": [HumanMessage(content=\"We need to gather information about customer preferences\")]\n",
    "    })\n",
    "    print(\"Research Task Result:\")\n",
    "    for message in result1[\"messages\"]:\n",
    "        print(f\"- {message.content}\")\n",
    "    print()\n",
    "    \n",
    "    # Test with analysis task\n",
    "    result2 = graph.invoke({\n",
    "        \"messages\": [HumanMessage(content=\"Analyze the sales data trends\")]\n",
    "    })\n",
    "    print(\"Analysis Task Result:\")\n",
    "    for message in result2[\"messages\"]:\n",
    "        print(f\"- {message.content}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "212f01dc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
