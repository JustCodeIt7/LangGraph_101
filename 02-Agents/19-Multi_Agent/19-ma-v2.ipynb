{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ca6c06ab",
   "metadata": {},
   "source": [
    "# Multi-Agent System\n",
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b529ce5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from typing import Annotated, Any, Literal, TypedDict\n",
    "\n",
    "from langchain_core.messages import (AIMessage, AnyMessage, HumanMessage,\n",
    "                                     ToolMessage)\n",
    "from langchain_ollama import ChatOllama, OllamaEmbeddings\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.graph import END, START, MessageGraph, MessagesState, StateGraph\n",
    "from langgraph.prebuilt import ToolNode\n",
    "from langgraph.types import Command\n",
    "\n",
    "llm = ChatOllama(model='phi4-mini')\n",
    "embedding = OllamaEmbeddings(model='nomic-embed-text')  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db89ee66",
   "metadata": {},
   "source": [
    "## 1. Supervisor Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0b6854bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "What's the capital of Japan?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Tokyo\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Compute 12*(3+4)\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "24\n"
     ]
    }
   ],
   "source": [
    "class State(MessagesState):\n",
    "    result: str\n",
    "\n",
    "\n",
    "def last_user(state: State) -> str:\n",
    "    for msg in reversed(state['messages']):\n",
    "        if getattr(msg, 'type', getattr(msg, 'role', '')) in ('human', 'user'):\n",
    "            return msg.content if hasattr(msg, 'content') else msg.get('content', '')\n",
    "    return ''\n",
    "\n",
    "\n",
    "def supervisor(state: State):\n",
    "    if state.get('result'):\n",
    "        return Command(goto='finish', update={})\n",
    "    q = last_user(state).lower()\n",
    "    if any(op in q for op in ['+', '-', '*', '/', 'solve', 'calc']):\n",
    "        return Command(goto='math', update={})\n",
    "    return Command(goto='research', update={})\n",
    "\n",
    "\n",
    "def research_agent(state: State):\n",
    "    q = last_user(state)\n",
    "    resp = llm.invoke([HumanMessage(content=f'Answer briefly and factually: {q}')])\n",
    "    return Command(goto='supervisor', update={'result': resp.content})\n",
    "\n",
    "\n",
    "def math_agent(state: State):\n",
    "    q = last_user(state)\n",
    "    prompt = f'Solve the math expression or question. Reply with the final answer only:\\n{q}'\n",
    "    resp = llm.invoke([HumanMessage(content=prompt)])\n",
    "    return Command(goto='supervisor', update={'result': resp.content.strip()})\n",
    "\n",
    "\n",
    "def finish(state: State):\n",
    "    return Command(goto=END, update={'messages': [AIMessage(content=state.get('result', 'No result'))]})\n",
    "\n",
    "\n",
    "builder = StateGraph(State)\n",
    "builder.add_node('supervisor', supervisor)\n",
    "builder.add_node('research', research_agent)\n",
    "builder.add_node('math', math_agent)\n",
    "builder.add_node('finish', finish)\n",
    "builder.add_edge(START, 'supervisor')\n",
    "graph_supervisor = builder.compile()\n",
    "\n",
    "# Demo usage (uncomment to run)\n",
    "out = graph_supervisor.invoke({'messages': [HumanMessage(\"What's the capital of Japan?\")]})\n",
    "for m in out['messages']:\n",
    "    m.pretty_print()\n",
    "out = graph_supervisor.invoke({'messages': [HumanMessage('Compute 12*(3+4)')]})\n",
    "for m in out['messages']:\n",
    "    m.pretty_print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd8b26eb",
   "metadata": {},
   "source": [
    "## 2. Network Architecture\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ff4a04eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Network Collaboration Result:\n",
      "1. We need to develop a strategy for market expansion\n",
      "\n",
      "2. Analyst: I've reviewed 'We need to develop a strategy for market expansion'. The data suggests we need deeper investigation.\n",
      "\n",
      "3. Strategist: For 'Analyst: I've reviewed 'We need to develop a strategy for market expansion'. The data suggests we need deeper investigation.', I recommend a comprehensive approach combining multiple perspectives.\n",
      "\n",
      "4. Analyst: I've reviewed 'Strategist: For 'Analyst: I've reviewed 'We need to develop a strategy for market expansion'. The data suggests we need deeper investigation.', I recommend a comprehensive approach combining multiple perspectives.'. The data suggests we need deeper investigation.\n",
      "\n",
      "5. Strategist: Final recommendation compiled. All agents have contributed to the solution.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "class NetworkState(MessagesState):\n",
    "    \"\"\"State for network of collaborating agents\"\"\"\n",
    "\n",
    "    iteration_count: int = 0\n",
    "\n",
    "\n",
    "# Network Agents - each can route to any other\n",
    "def analyst_agent(state: NetworkState) -> Command[Literal['researcher_agent', 'strategist_agent', '__end__']]:\n",
    "    \"\"\"Analyst agent that processes data and routes accordingly\"\"\"\n",
    "    last_message = state['messages'][-1].content\n",
    "    response = f\"Analyst: I've reviewed '{last_message}'. The data suggests we need deeper investigation.\"\n",
    "    new_state = {'messages': [AIMessage(content=response)], 'iteration_count': state.get('iteration_count', 0) + 1}\n",
    "    if state.get('iteration_count', 0) >= 3:\n",
    "        return Command(goto='__end__', update=new_state)\n",
    "    elif 'strategy' in last_message.lower():\n",
    "        return Command(goto='strategist_agent', update=new_state)\n",
    "    else:\n",
    "        return Command(goto='researcher_agent', update=new_state)\n",
    "\n",
    "\n",
    "def researcher_agent(state: NetworkState) -> Command[Literal['analyst_agent', 'strategist_agent', '__end__']]:\n",
    "    \"\"\"Researcher agent that gathers information\"\"\"\n",
    "    last_message = state['messages'][-1].content\n",
    "    response = f\"Researcher: Based on my investigation of '{last_message}', I found relevant background information.\"\n",
    "    new_state = {'messages': [AIMessage(content=response)], 'iteration_count': state.get('iteration_count', 0) + 1}\n",
    "    if state.get('iteration_count', 0) >= 3:\n",
    "        return Command(goto='__end__', update=new_state)\n",
    "    elif 'analysis' in last_message.lower():\n",
    "        return Command(goto='analyst_agent', update=new_state)\n",
    "    else:\n",
    "        return Command(goto='strategist_agent', update=new_state)\n",
    "\n",
    "\n",
    "def strategist_agent(state: NetworkState) -> Command[Literal['analyst_agent', 'researcher_agent', '__end__']]:\n",
    "    \"\"\"Strategist agent that develops plans\"\"\"\n",
    "    last_message = state['messages'][-1].content\n",
    "    response = (\n",
    "        f\"Strategist: For '{last_message}', I recommend a comprehensive approach combining multiple perspectives.\"\n",
    "    )\n",
    "    new_state = {'messages': [AIMessage(content=response)], 'iteration_count': state.get('iteration_count', 0) + 1}\n",
    "    if state.get('iteration_count', 0) >= 2:\n",
    "        final_response = 'Strategist: Final recommendation compiled. All agents have contributed to the solution.'\n",
    "        return Command(goto='__end__', update={'messages': [AIMessage(content=final_response)]})\n",
    "    else:\n",
    "        return Command(goto='analyst_agent', update=new_state)\n",
    "\n",
    "\n",
    "# Build the network graph\n",
    "def create_network_graph():\n",
    "    workflow = StateGraph(NetworkState)\n",
    "    workflow.add_node('analyst_agent', analyst_agent)\n",
    "    workflow.add_node('researcher_agent', researcher_agent)\n",
    "    workflow.add_node('strategist_agent', strategist_agent)\n",
    "    workflow.set_entry_point('analyst_agent')\n",
    "    return workflow.compile()\n",
    "\n",
    "\n",
    "# Usage example (uncomment to run)\n",
    "# if __name__ == '__main__':\n",
    "graph_network = create_network_graph()\n",
    "result = graph_network.invoke(\n",
    "    {'messages': [HumanMessage(content='We need to develop a strategy for market expansion')], 'iteration_count': 0}\n",
    ")\n",
    "print('Network Collaboration Result:')\n",
    "for i, message in enumerate(result['messages']):\n",
    "    print(f'{i + 1}. {message.content}')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9c14314",
   "metadata": {},
   "source": [
    "## 3. Hierarchical Architecture\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a0bf0a35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Who created Python?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Python was developed by Guido van Rossum.\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Quickly estimate 20*(5-2).\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "A quick mental calculation of \\(20 \\times (5 - 2)\\) is straightforward and accurate, earning this problem an average difficulty rating with minor room for error: Score 0.7/1.\n",
      "\n",
      "Reasoning:\n",
      "The subtraction inside the parentheses (\\(5-2\\)) equals 3.\n",
      "Multiplying by 20 gives us:\n",
      "\n",
      "\\(20 \\times 3 = 60.\\)\n",
      "\n",
      "While there is always a slight chance of human errors, most people should be able to calculate this correctly quickly under normal conditions. Thus, I awarded it an average score reflecting its elementary nature but acknowledging potential minor inaccuracies.\n",
      "\n",
      "Note: This simplified rating considers common arithmetic abilities and standard mental math performance without factoring in any advanced mathematical considerations or extreme difficulty levels that would significantly lower the accuracy percentage (thus closer to 1).\n"
     ]
    }
   ],
   "source": [
    "class TopState(MessagesState):\n",
    "    data: str\n",
    "    notes: str\n",
    "\n",
    "\n",
    "def last_user(s: TopState) -> str:\n",
    "    for m in reversed(s['messages']):\n",
    "        if getattr(m, 'type', getattr(m, 'role', '')) in ('human', 'user'):\n",
    "            return m.content if hasattr(m, 'content') else m.get('content', '')\n",
    "    return ''\n",
    "\n",
    "\n",
    "DOCS = [\n",
    "    'Python was created by Guido van Rossum.',\n",
    "    'The capital of Japan is Tokyo.',\n",
    "    'LangGraph helps build multi-agent workflows.',\n",
    "]\n",
    "V_DOCS = [embedding.embed_query(d) for d in DOCS]\n",
    "\n",
    "\n",
    "def gather(state: TopState):\n",
    "    q = last_user(state)\n",
    "    qv = embedding.embed_query(q)\n",
    "    idx = max(range(len(DOCS)), key=lambda i: sum(a * b for a, b in zip(V_DOCS[i], qv)))\n",
    "    return {'data': DOCS[idx]}\n",
    "\n",
    "\n",
    "def synthesize(state: TopState):\n",
    "    prompt = f'Using this note, answer the user briefly:\\nNote: {state.get(\"data\", \"\")}\\nUser: {last_user(state)}'\n",
    "    resp = llm.invoke([HumanMessage(content=prompt)])\n",
    "    return {'notes': resp.content}\n",
    "\n",
    "\n",
    "def compute(state: TopState):\n",
    "    q = last_user(state)\n",
    "    resp = llm.invoke([HumanMessage(content=f'Analyze and give a score 0-1 with a reason for: {q}')])\n",
    "    return {'data': resp.content}\n",
    "\n",
    "\n",
    "def summarize(state: TopState):\n",
    "    resp = llm.invoke([HumanMessage(content=f'Summarize to one sentence: {state.get(\"data\", \"\")}')])\n",
    "    return {'notes': resp.content}\n",
    "\n",
    "\n",
    "# Research subgraph\n",
    "r = StateGraph(TopState)\n",
    "r.add_node('gather', gather)\n",
    "r.add_node('synth', synthesize)\n",
    "r.add_edge(START, 'gather')\n",
    "r.add_edge('gather', 'synth')\n",
    "r.add_edge('synth', END)\n",
    "research_team = r.compile()\n",
    "\n",
    "# Analysis subgraph\n",
    "a = StateGraph(TopState)\n",
    "a.add_node('compute', compute)\n",
    "a.add_node('summary', summarize)\n",
    "a.add_edge(START, 'compute')\n",
    "a.add_edge('compute', 'summary')\n",
    "a.add_edge('summary', END)\n",
    "analysis_team = a.compile()\n",
    "\n",
    "\n",
    "def supervisor(state: TopState):\n",
    "    q = last_user(state).lower()\n",
    "    if state.get('notes'):\n",
    "        return Command(goto='final', update={})\n",
    "    if any(op in q for op in ['+', '-', '*', '/', 'calc', 'solve']):\n",
    "        return Command(goto='analysis_team', update={})\n",
    "    return Command(goto='research_team', update={})\n",
    "\n",
    "\n",
    "def final_node(state: TopState):\n",
    "    return Command(goto=END, update={'messages': [AIMessage(content=state.get('notes', 'No notes'))]})\n",
    "\n",
    "\n",
    "b = StateGraph(TopState)\n",
    "b.add_node('supervisor', supervisor)\n",
    "b.add_node('research_team', research_team)\n",
    "b.add_node('analysis_team', analysis_team)\n",
    "b.add_node('final', final_node)\n",
    "b.add_edge(START, 'supervisor')\n",
    "b.add_edge('research_team', 'final')\n",
    "b.add_edge('analysis_team', 'final')\n",
    "graph_hierarchical = b.compile()\n",
    "\n",
    "# Demo usage (uncomment to run)\n",
    "out = graph_hierarchical.invoke({'messages': [HumanMessage('Who created Python?')]})\n",
    "for m in out['messages']:\n",
    "    m.pretty_print()\n",
    "out = graph_hierarchical.invoke({'messages': [HumanMessage('Quickly estimate 20*(5-2).')]})\n",
    "for m in out['messages']:\n",
    "    m.pretty_print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "975fbd81",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
