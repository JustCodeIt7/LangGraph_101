{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ca6c06ab",
   "metadata": {},
   "source": [
    "# Multi-Agent System\n",
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b529ce5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from typing import Annotated, Any, Literal, TypedDict\n",
    "\n",
    "from langchain_core.messages import (AIMessage, AnyMessage, HumanMessage,\n",
    "                                     ToolMessage)\n",
    "from langchain_ollama import ChatOllama, OllamaEmbeddings\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.graph import END, START, MessageGraph, MessagesState, StateGraph\n",
    "from langgraph.prebuilt import ToolNode\n",
    "from langgraph.types import Command\n",
    "\n",
    "llm = ChatOllama(model='phi4-mini')\n",
    "embedding = OllamaEmbeddings(model='nomic-embed-text')  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db89ee66",
   "metadata": {},
   "source": [
    "## 1. Supervisor Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "supervisor-explanation",
   "metadata": {},
   "source": [
    "This architecture uses a central \"supervisor\" node to route tasks to specialized agents. It's a common and effective pattern for managing workflows where different agents have distinct capabilities.\n",
    "\n",
    "### Key Concepts\n",
    "\n",
    "- **State Management**: The `State` class inherits from `MessagesState` and adds a `result` field. This shared state is how agents pass information and results to each other.\n",
    "- **Conditional Routing**: The `supervisor` node acts as a conditional router. It inspects the user's query and decides which agent (`math` or `research`) should handle it. This is a core concept in LangGraph for creating dynamic and intelligent workflows.\n",
    "- **Nodes and Edges**: The graph is built by adding nodes (the supervisor and the agents) and edges (the connections between them). The `START` and `END` keywords are special nodes that define the beginning and end of the graph's execution.\n",
    "- **Command Class**: The `Command` class is used to control the flow of the graph. It allows a node to specify which node to go to next (`goto`) and what data to update in the state (`update`).\n",
    "\n",
    "### Execution Flow\n",
    "\n",
    "1.  **Start**: The graph starts at the `supervisor` node.\n",
    "2.  **Supervision**: The `supervisor` checks if a result is already present. If so, it routes to the `finish` node. Otherwise, it examines the last user message.\n",
    "3.  **Routing**:\n",
    "    *   If the message contains math-related keywords, it routes to the `math` agent.\n",
    "    *   Otherwise, it routes to the `research` agent.\n",
    "4.  **Agent Execution**: The selected agent (either `math` or `research`) processes the user's query and produces a result.\n",
    "5.  **Return to Supervisor**: After execution, the agent routes back to the `supervisor`, updating the state with the `result`.\n",
    "6.  **Finish**: The `supervisor` now sees a result in the state and routes to the `finish` node.\n",
    "7.  **End**: The `finish` node formats the final output and terminates the graph execution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0b6854bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "What's the capital of Japan?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Tokyo\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Compute 12*(3+4)\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "24\n"
     ]
    }
   ],
   "source": [
    "class State(MessagesState):\n",
    "    result: str\n",
    "\n",
    "\n",
    "def last_user(state: State) -> str:\n",
    "    for msg in reversed(state['messages']):\n",
    "        if getattr(msg, 'type', getattr(msg, 'role', '')) in ('human', 'user'):\n",
    "            return msg.content if hasattr(msg, 'content') else msg.get('content', '')\n",
    "    return ''\n",
    "\n",
    "\n",
    "def supervisor(state: State):\n",
    "    if state.get('result'):\n",
    "        return Command(goto='finish', update={})\n",
    "    q = last_user(state).lower()\n",
    "    if any(op in q for op in ['+', '-', '*', '/', 'solve', 'calc']):\n",
    "        return Command(goto='math', update={})\n",
    "    return Command(goto='research', update={})\n",
    "\n",
    "\n",
    "def research_agent(state: State):\n",
    "    q = last_user(state)\n",
    "    resp = llm.invoke([HumanMessage(content=f'Answer briefly and factually: {q}')])\n",
    "    return Command(goto='supervisor', update={'result': resp.content})\n",
    "\n",
    "\n",
    "def math_agent(state: State):\n",
    "    q = last_user(state)\n",
    "    prompt = f'Solve the math expression or question. Reply with the final answer only:\\n{q}'\n",
    "    resp = llm.invoke([HumanMessage(content=prompt)])\n",
    "    return Command(goto='supervisor', update={'result': resp.content.strip()})\n",
    "\n",
    "\n",
    "def finish(state: State):\n",
    "    return Command(goto=END, update={'messages': [AIMessage(content=state.get('result', 'No result'))]})\n",
    "\n",
    "\n",
    "builder = StateGraph(State)\n",
    "builder.add_node('supervisor', supervisor)\n",
    "builder.add_node('research', research_agent)\n",
    "builder.add_node('math', math_agent)\n",
    "builder.add_node('finish', finish)\n",
    "builder.add_edge(START, 'supervisor')\n",
    "graph_supervisor = builder.compile()\n",
    "\n",
    "# Demo usage (uncomment to run)\n",
    "out = graph_supervisor.invoke({'messages': [HumanMessage(\"What's the capital of Japan?\")]})\n",
    "for m in out['messages']:\n",
    "    m.pretty_print()\n",
    "out = graph_supervisor.invoke({'messages': [HumanMessage('Compute 12*(3+4)')]})\n",
    "for m in out['messages']:\n",
    "    m.pretty_print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd8b26eb",
   "metadata": {},
   "source": [
    "## 2. Network Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "network-explanation",
   "metadata": {},
   "source": [
    "This example demonstrates a network of collaborating agents where each agent can route to any other agent in the graph. This allows for more flexible and dynamic interactions compared to a strict hierarchy.\n",
    "\n",
    "### Key Concepts\n",
    "\n",
    "- **Peer-to-Peer Communication**: Unlike the supervisor model, agents in a network can communicate directly with each other. The `analyst_agent`, `researcher_agent`, and `strategist_agent` can all decide to pass control to one another.\n",
    "- **State-Driven Routing**: Each agent's routing decision is based on the current state, specifically the content of the last message. For example, the `analyst_agent` routes to the `strategist_agent` if the message contains the word \"strategy\".\n",
    "- **Looping and Iteration**: The agents can loop, passing control back and forth until a termination condition is met. In this case, the `iteration_count` in the `NetworkState` is used to prevent infinite loops.\n",
    "- **Dynamic Endpoints**: The `__end__` literal in the `Command`'s type hint signifies that an agent can decide to end the graph's execution.\n",
    "\n",
    "### Execution Flow\n",
    "\n",
    "1.  **Entry Point**: The graph starts with the `analyst_agent`.\n",
    "2.  **Analyst's Turn**: The `analyst_agent` processes the initial message and, based on its content, routes to either the `researcher_agent` or the `strategist_agent`.\n",
    "3.  **Agent Collaboration**: The agents pass control to each other based on the logic within each agent function. For instance, the `researcher_agent` might find information and pass it to the `analyst_agent` for review.\n",
    "4.  **Iteration Limit**: The `iteration_count` is incremented each time an agent is called. The graph will terminate if this count exceeds a certain threshold (in this case, 3 for most agents, 2 for the strategist).\n",
    "5.  **Termination**: The graph ends when an agent routes to `__end__`, which happens either when the iteration limit is reached or when the `strategist_agent` has compiled a final recommendation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ff4a04eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Network Collaboration Result:\n",
      "1. We need to develop a strategy for market expansion\n",
      "\n",
      "2. Analyst: I've reviewed 'We need to develop a strategy for market expansion'. The data suggests we need deeper investigation.\n",
      "\n",
      "3. Strategist: For 'Analyst: I've reviewed 'We need to develop a strategy for market expansion'. The data suggests we need deeper investigation.', I recommend a comprehensive approach combining multiple perspectives.\n",
      "\n",
      "4. Analyst: I've reviewed 'Strategist: For 'Analyst: I've reviewed 'We need to develop a strategy for market expansion'. The data suggests we need deeper investigation.', I recommend a comprehensive approach combining multiple perspectives.'. The data suggests we need deeper investigation.\n",
      "\n",
      "5. Strategist: Final recommendation compiled. All agents have contributed to the solution.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "class NetworkState(MessagesState):\n",
    "    \"\"\"State for network of collaborating agents\"\"\"\n",
    "\n",
    "    iteration_count: int = 0\n",
    "\n",
    "\n",
    "# Network Agents - each can route to any other\n",
    "def analyst_agent(state: NetworkState) -> Command[Literal['researcher_agent', 'strategist_agent', '__end__']]:\n",
    "    \"\"\"Analyst agent that processes data and routes accordingly\"\"\"\n",
    "    last_message = state['messages'][-1].content\n",
    "    response = f\"Analyst: I've reviewed '{last_message}'. The data suggests we need deeper investigation.\"\n",
    "    new_state = {'messages': [AIMessage(content=response)], 'iteration_count': state.get('iteration_count', 0) + 1}\n",
    "    if state.get('iteration_count', 0) >= 3:\n",
    "        return Command(goto='__end__', update=new_state)\n",
    "    elif 'strategy' in last_message.lower():\n",
    "        return Command(goto='strategist_agent', update=new_state)\n",
    "    else:\n",
    "        return Command(goto='researcher_agent', update=new_state)\n",
    "\n",
    "\n",
    "def researcher_agent(state: NetworkState) -> Command[Literal['analyst_agent', 'strategist_agent', '__end__']]:\n",
    "    \"\"\"Researcher agent that gathers information\"\"\"\n",
    "    last_message = state['messages'][-1].content\n",
    "    response = f\"Researcher: Based on my investigation of '{last_message}', I found relevant background information.\"\n",
    "    new_state = {'messages': [AIMessage(content=response)], 'iteration_count': state.get('iteration_count', 0) + 1}\n",
    "    if state.get('iteration_count', 0) >= 3:\n",
    "        return Command(goto='__end__', update=new_state)\n",
    "    elif 'analysis' in last_message.lower():\n",
    "        return Command(goto='analyst_agent', update=new_state)\n",
    "    else:\n",
    "        return Command(goto='strategist_agent', update=new_state)\n",
    "\n",
    "\n",
    "def strategist_agent(state: NetworkState) -> Command[Literal['analyst_agent', 'researcher_agent', '__end__']]:\n",
    "    \"\"\"Strategist agent that develops plans\"\"\"\n",
    "    last_message = state['messages'][-1].content\n",
    "    response = (\n",
    "        f\"Strategist: For '{last_message}', I recommend a comprehensive approach combining multiple perspectives.\"\n",
    "    )\n",
    "    new_state = {'messages': [AIMessage(content=response)], 'iteration_count': state.get('iteration_count', 0) + 1}\n",
    "    if state.get('iteration_count', 0) >= 2:\n",
    "        final_response = 'Strategist: Final recommendation compiled. All agents have contributed to the solution.'\n",
    "        return Command(goto='__end__', update={'messages': [AIMessage(content=final_response)]})\n",
    "    else:\n",
    "        return Command(goto='analyst_agent', update=new_state)\n",
    "\n",
    "\n",
    "# Build the network graph\n",
    "def create_network_graph():\n",
    "    workflow = StateGraph(NetworkState)\n",
    "    workflow.add_node('analyst_agent', analyst_agent)\n",
    "    workflow.add_node('researcher_agent', researcher_agent)\n",
    "    workflow.add_node('strategist_agent', strategist_agent)\n",
    "    workflow.set_entry_point('analyst_agent')\n",
    "    return workflow.compile()\n",
    "\n",
    "\n",
    "# Usage example (uncomment to run)\n",
    "# if __name__ == '__main__':\n",
    "graph_network = create_network_graph()\n",
    "result = graph_network.invoke(\n",
    "    {'messages': [HumanMessage(content='We need to develop a strategy for market expansion')], 'iteration_count': 0}\n",
    ")\n",
    "print('Network Collaboration Result:')\n",
    "for i, message in enumerate(result['messages']):\n",
    "    print(f'{i + 1}. {message.content}')\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9c14314",
   "metadata": {},
   "source": [
    "## 3. Hierarchical Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hierarchical-explanation",
   "metadata": {},
   "source": [
    "This architecture organizes agents into teams, or subgraphs, which are then orchestrated by a top-level supervisor. This is useful for breaking down complex problems into smaller, manageable parts.\n",
    "\n",
    "### Key Concepts\n",
    "\n",
    "- **Subgraphs**: The `research_team` and `analysis_team` are themselves complete LangGraphs. These subgraphs are then used as nodes in the main graph. This allows for modular and reusable components.\n",
    "- **Hierarchical Control**: The top-level `supervisor` decides which team (subgraph) to delegate the task to. This is a powerful way to manage complexity, as the supervisor only needs to know about the teams, not the individual agents within them.\n",
    "- **State Propagation**: The state (`TopState`) is passed down from the main graph to the subgraphs. This means that the agents within the subgraphs have access to the same information as the top-level supervisor.\n",
    "- **Encapsulation**: Each subgraph is self-contained. The `research_team` has its own internal logic (`gather` and `synth`), and the `analysis_team` has its own (`compute` and `summary`). This makes the overall system easier to understand and maintain.\n",
    "\n",
    "### Execution Flow\n",
    "\n",
    "1.  **Top-Level Supervision**: The graph starts at the top-level `supervisor`.\n",
    "2.  **Delegation**: The supervisor inspects the user's query and routes the task to either the `research_team` or the `analysis_team`.\n",
    "3.  **Subgraph Execution**: The selected subgraph executes its internal workflow. For example, if the `research_team` is chosen, it will first `gather` data and then `synthesize` it.\n",
    "4.  **Return to Main Graph**: Once the subgraph has finished, it returns control to the main graph.\n",
    "5.  **Final Node**: The main graph then routes to the `final` node, which formats the output from the `notes` field in the state.\n",
    "6.  **End**: The graph execution terminates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a0bf0a35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Who created Python?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Python was created by Guido van Rossum.\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Quickly estimate 20*(5-2).\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "I will quickly analyze the expression `20 * (5 - 2)` by first calculating inside the parentheses `(5 - 2) = 3` and then multiplying to get `20 * 3 = 60`. This straightforward arithmetic yields an accuracy score of `1 (100%)`, as there are no errors or uncertainties involved.\n"
     ]
    }
   ],
   "source": [
    "class TopState(MessagesState):\n",
    "    data: str\n",
    "    notes: str\n",
    "\n",
    "\n",
    "def last_user(s: TopState) -> str:\n",
    "    for m in reversed(s['messages']):\n",
    "        if getattr(m, 'type', getattr(m, 'role', '')) in ('human', 'user'):\n",
    "            return m.content if hasattr(m, 'content') else m.get('content', '')\n",
    "    return ''\n",
    "\n",
    "\n",
    "DOCS = [\n",
    "    'Python was created by Guido van Rossum.',\n",
    "    'The capital of Japan is Tokyo.',\n",
    "    'LangGraph helps build multi-agent workflows.',\n",
    "]\n",
    "V_DOCS = [embedding.embed_query(d) for d in DOCS]\n",
    "\n",
    "\n",
    "def gather(state: TopState):\n",
    "    q = last_user(state)\n",
    "    qv = embedding.embed_query(q)\n",
    "    idx = max(range(len(DOCS)), key=lambda i: sum(a * b for a, b in zip(V_DOCS[i], qv)))\n",
    "    return {'data': DOCS[idx]}\n",
    "\n",
    "\n",
    "def synthesize(state: TopState):\n",
    "    prompt = f'Using this note, answer the user briefly:\\nNote: {state.get(\"data\", \"\")}\\nUser: {last_user(state)}'\n",
    "    resp = llm.invoke([HumanMessage(content=prompt)])\n",
    "    return {'notes': resp.content}\n",
    "\n",
    "\n",
    "def compute(state: TopState):\n",
    "    q = last_user(state)\n",
    "    resp = llm.invoke([HumanMessage(content=f'Analyze and give a score 0-1 with a reason for: {q}')])\n",
    "    return {'data': resp.content}\n",
    "\n",
    "\n",
    "def summarize(state: TopState):\n",
    "    resp = llm.invoke([HumanMessage(content=f'Summarize to one sentence: {state.get(\"data\", \"\")}')])\n",
    "    return {'notes': resp.content}\n",
    "\n",
    "\n",
    "# Research subgraph\n",
    "r = StateGraph(TopState)\n",
    "r.add_node('gather', gather)\n",
    "r.add_node('synth', synthesize)\n",
    "r.add_edge(START, 'gather')\n",
    "r.add_edge('gather', 'synth')\n",
    "r.add_edge('synth', END)\n",
    "research_team = r.compile()\n",
    "\n",
    "# Analysis subgraph\n",
    "a = StateGraph(TopState)\n",
    "a.add_node('compute', compute)\n",
    "a.add_node('summary', summarize)\n",
    "a.add_edge(START, 'compute')\n",
    "a.add_edge('compute', 'summary')\n",
    "a.add_edge('summary', END)\n",
    "analysis_team = a.compile()\n",
    "\n",
    "\n",
    "def supervisor(state: TopState):\n",
    "    q = last_user(state).lower()\n",
    "    if state.get('notes'):\n",
    "        return Command(goto='final', update={})\n",
    "    if any(op in q for op in ['+', '-', '*', '/', 'calc', 'solve']):\n",
    "        return Command(goto='analysis_team', update={})\n",
    "    return Command(goto='research_team', update={})\n",
    "\n",
    "\n",
    "def final_node(state: TopState):\n",
    "    return Command(goto=END, update={'messages': [AIMessage(content=state.get('notes', 'No notes'))]})\n",
    "\n",
    "\n",
    "b = StateGraph(TopState)\n",
    "b.add_node('supervisor', supervisor)\n",
    "b.add_node('research_team', research_team)\n",
    "b.add_node('analysis_team', analysis_team)\n",
    "b.add_node('final', final_node)\n",
    "b.add_edge(START, 'supervisor')\n",
    "b.add_edge('research_team', 'final')\n",
    "b.add_edge('analysis_team', 'final')\n",
    "graph_hierarchical = b.compile()\n",
    "\n",
    "# Demo usage (uncomment to run)\n",
    "out = graph_hierarchical.invoke({'messages': [HumanMessage('Who created Python?')]})\n",
    "for m in out['messages']:\n",
    "    m.pretty_print()\n",
    "out = graph_hierarchical.invoke({'messages': [HumanMessage('Quickly estimate 20*(5-2).')]})\n",
    "for m in out['messages']:\n",
    "    m.pretty_print()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
