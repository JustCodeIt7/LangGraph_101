{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3ffd9b53",
   "metadata": {},
   "source": [
    "# Sequential Graphs\n",
    "## Basic Chatbot \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cd1550d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from typing import TypedDict # Imports all the data types we need\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langchain_ollama import ChatOllama\n",
    "from dotenv import load_dotenv\n",
    "from rich import print\n",
    "# Load environment variables from .env file\n",
    "load_dotenv('../.env')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3234b693",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Hello! It's nice to meet you. Is there something I can help you with or would you like to chat?\""
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm = ChatOllama(model=\"llama3.2\")\n",
    "llm.invoke(\"Hello, world!\").content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "91d031e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AgentState(TypedDict):\n",
    "    name: str\n",
    "    age: str\n",
    "    final: str\n",
    "    message: str"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "348a2a1b",
   "metadata": {},
   "source": [
    "### Node Fuctions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "98571c7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def greating_message(state: AgentState) -> AgentState:\n",
    "    \"\"\"Function to greet the user and initialize the state.\"\"\"\n",
    "    print(\"Welcome to the chatbot!\")\n",
    "    state['name'] = input(\"What is your name? \")\n",
    "    state['age'] = input(\"How old are you? \")\n",
    "    \n",
    "    return state\n",
    "\n",
    "def chatbot(state: AgentState) -> AgentState:\n",
    "    \"\"\"Chatbot function that updates the state with user input.\"\"\"\n",
    "    user_input = input(\"You: \")\n",
    "    state['message'] = llm.invoke(user_input).content\n",
    "    print(f\"Chatbot: {state['message']}\")\n",
    "    return state\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "769ce08e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/m7/yjmck8kn59gc9w3kdklj2lt40000gn/T/ipykernel_70971/3948258616.py:25: LangChainDeprecationWarning: The class `ChatOpenAI` was deprecated in LangChain 0.0.10 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import ChatOpenAI``.\n",
      "  model = ChatOpenAI(model_name=\"gpt-3.5-turbo\")\n",
      "/var/folders/m7/yjmck8kn59gc9w3kdklj2lt40000gn/T/ipykernel_70971/3948258616.py:26: LangChainDeprecationWarning: The method `BaseChatModel.__call__` was deprecated in langchain-core 0.1.7 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  response: AIMessage = model(history)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Hi Alice!\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "What's the capital of France?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "The capital of France is Paris.\n"
     ]
    }
   ],
   "source": [
    "# simple_chatbot.py\n",
    "\n",
    "from typing_extensions import TypedDict\n",
    "from langchain_core.messages import HumanMessage, AIMessage, AnyMessage\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "# 1) Define the shared state schema\n",
    "class State(TypedDict):\n",
    "    name: str\n",
    "    user_question: str\n",
    "    messages: list[AnyMessage]\n",
    "\n",
    "# 2) Node 1: Greet the user by name\n",
    "def greet(state: State) -> dict:\n",
    "    greeting = AIMessage(f\"Hi {state['name']}!\")\n",
    "    # Append to existing messages\n",
    "    return {\"messages\": state.get(\"messages\", []) + [greeting]}\n",
    "\n",
    "# 3) Node 2: Take the user's question and get an LLM response\n",
    "def answer(state: State) -> dict:\n",
    "    # Build the message history: include the user's question\n",
    "    history = state[\"messages\"] + [HumanMessage(state[\"user_question\"])]\n",
    "    # Call the chat model\n",
    "    model = ChatOpenAI(model_name=\"gpt-3.5-turbo\")\n",
    "    response: AIMessage = model(history)\n",
    "    return {\"messages\": history + [response]}\n",
    "\n",
    "# 4) Assemble the graph\n",
    "builder = StateGraph(State)\n",
    "builder.add_node(greet)\n",
    "builder.add_node(answer)\n",
    "# Define control flow: START → greet → answer → END\n",
    "builder.add_edge(START, \"greet\")\n",
    "builder.add_edge(\"greet\", \"answer\")\n",
    "builder.add_edge(\"answer\", END)\n",
    "graph = builder.compile()\n",
    "\n",
    "# 5) Invoke the graph\n",
    "initial_state = {\n",
    "    \"name\": \"Alice\",\n",
    "    \"user_question\": \"What's the capital of France?\",\n",
    "    \"messages\": []\n",
    "}\n",
    "result = graph.invoke(initial_state)\n",
    "\n",
    "# 6) Print out the conversation\n",
    "for msg in result[\"messages\"]:\n",
    "    msg.pretty_print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e79d86e3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
