{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2d0c022a",
   "metadata": {},
   "source": [
    "# Sequential Graphs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7502bdad",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "This notebook demonstrates how to build sequential graphs for chatbot workflows using LangGraph and LangChain."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "babebd25",
   "metadata": {},
   "source": [
    "## Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c88afbb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import TypedDict\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langchain_ollama import ChatOllama\n",
    "from dotenv import load_dotenv\n",
    "from rich import print\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv('../.env')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f3321f2",
   "metadata": {},
   "source": [
    "## Basic Chatbot Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28af0f66",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOllama(model=\"llama3.2\")\n",
    "llm.invoke(\"Hello, world!\").content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e16a7ab7",
   "metadata": {},
   "source": [
    "### Agent State Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9baf451",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AgentState(TypedDict):\n",
    "    name: str\n",
    "    age: str\n",
    "    final: str\n",
    "    message: str"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6002fbe",
   "metadata": {},
   "source": [
    "### Node Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "906130c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def greating_message(state: AgentState) -> AgentState:\n",
    "    \"\"\"Function to greet the user and initialize the state.\"\"\"\n",
    "    print(\"Welcome to the chatbot!\")\n",
    "    state['name'] = input(\"What is your name? \")\n",
    "    state['age'] = input(\"How old are you? \")\n",
    "    return state\n",
    "\n",
    "def chatbot(state: AgentState) -> AgentState:\n",
    "    \"\"\"Chatbot function that updates the state with user input.\"\"\"\n",
    "    user_input = input(\"You: \")\n",
    "    state['message'] = llm.invoke(user_input).content\n",
    "    print(f\"Chatbot: {state['message']}\")\n",
    "    return state"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a59afd2",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8469eb16",
   "metadata": {},
   "source": [
    "## Sequential Graph with LangGraph and LangChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b9f4a0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# simple_chatbot.py\n",
    "from typing_extensions import TypedDict\n",
    "from langchain_core.messages import HumanMessage, AIMessage, AnyMessage\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langchain.chat_models import ChatOpenAI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37b192ea",
   "metadata": {},
   "source": [
    "### 1. Define the Shared State Schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b861c57",
   "metadata": {},
   "outputs": [],
   "source": [
    "class State(TypedDict):\n",
    "    name: str\n",
    "    user_question: str\n",
    "    messages: list[AnyMessage]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e677432a",
   "metadata": {},
   "source": [
    "### 2. Node 1: Greet the User by Name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5372d02",
   "metadata": {},
   "outputs": [],
   "source": [
    "def greet(state: State) -> dict:\n",
    "    greeting = AIMessage(f\"Hi {state['name']}!\")\n",
    "    # Append to existing messages\n",
    "    return {\"messages\": state.get(\"messages\", []) + [greeting]}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57bc15b7",
   "metadata": {},
   "source": [
    "### 3. Node 2: Take the User's Question and Get an LLM Response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ff631e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def answer(state: State) -> dict:\n",
    "    # Build the message history: include the user's question\n",
    "    history = state[\"messages\"] + [HumanMessage(state[\"user_question\"])]\n",
    "    # Call the chat model\n",
    "    model = ChatOpenAI(model_name=\"gpt-3.5-turbo\")\n",
    "    response: AIMessage = model(history)\n",
    "    return {\"messages\": history + [response]}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "863208ab",
   "metadata": {},
   "source": [
    "### 4. Assemble the Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e85a929",
   "metadata": {},
   "outputs": [],
   "source": [
    "builder = StateGraph(State)\n",
    "builder.add_node(greet)\n",
    "builder.add_node(answer)\n",
    "# Define control flow: START → greet → answer → END\n",
    "builder.add_edge(START, \"greet\")\n",
    "builder.add_edge(\"greet\", \"answer\")\n",
    "builder.add_edge(\"answer\", END)\n",
    "graph = builder.compile()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5c65839",
   "metadata": {},
   "source": [
    "### 5. Invoke the Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff0b73ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_state = {\n",
    "    \"name\": \"Alice\",\n",
    "    \"user_question\": \"What's the capital of France?\",\n",
    "    \"messages\": []\n",
    "}\n",
    "result = graph.invoke(initial_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e710de37",
   "metadata": {},
   "source": [
    "### 6. Print Out the Conversation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4fdc1c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for msg in result[\"messages\"]:\n",
    "    msg.pretty_print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": ""
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
